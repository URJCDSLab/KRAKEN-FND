{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForSequenceClassification, BertPreTrainedModel, BertTokenizerFast, AdamW, BertConfig, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "IMAGES_PATH = '../data/images'\n",
    "AC_DATA_PATH = 'animal_crossing'\n",
    "DOOM_DATA_PATH = 'doom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_images_files = os.listdir(os.path.join(IMAGES_PATH, AC_DATA_PATH))\n",
    "doom_images_files = os.listdir(os.path.join(IMAGES_PATH, DOOM_DATA_PATH))\n",
    "ac_text_data = pd.read_csv(os.path.join(DATA_PATH, 'animal_crossing_dataset.csv'))\n",
    "doom_text_data = pd.read_csv(os.path.join(DATA_PATH, 'doom_dataset.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = (\n",
    "    [os.path.join(AC_DATA_PATH, p) for p in ac_images_files] +\n",
    "    [os.path.join(DOOM_DATA_PATH, p) for p in doom_images_files] \n",
    ")\n",
    "df = pd.DataFrame({\n",
    "    'filename': ac_images_files + doom_images_files,\n",
    "    'path': paths,\n",
    "    'ac': [True] * len(ac_images_files) + ([False] * len(doom_images_files)),\n",
    "    'doom': [False] * len(ac_images_files) + ([True] * len(doom_images_files)),\n",
    "})\n",
    "df = df.join(pd.concat([ac_text_data, doom_text_data])[['filename', 'title']].set_index('filename'), on='filename')\n",
    "# df['tokeniked'] = df.apply(lambda r: tokenizer(str(r['title']), padding=True, truncation=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(N=10):\n",
    "    df_train, df_test = train_test_split(df, train_size=N)\n",
    "\n",
    "    \n",
    "    return df_train[['path', 'ac', 'doom']], df_test[['path', 'ac', 'doom']], df_train[['title', 'ac', 'doom']], df_test[['title', 'ac', 'doom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_test, text_train, text_test = get_sets(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ac</th>\n",
       "      <th>doom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>Mick Gordon simp exposed</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Petition to re-rip the Classic Doom Marineâ€™s pants in Doom Eternal</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Scary movie night! Poor Stitches :(</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Stayed up till 4 AM finishing my magical study!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Thank you Lobo but Isabelle doesn't think the same way.. ðŸ˜”ðŸ˜”ðŸ˜”</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Met Redd today, seems like a pretty nice guy.</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Hope you guys like my AC grad cap!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>I drew Lily!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>Doom Slayer/Samuel Hayden chemistry in a nutshell</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>I dunno if something like this was posted before</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>So I Bought A Cacodemon Plush</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>Living breathing ammo box</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>Channel your inner Slayer, king</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Is this a pigeon?</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Nintendo watching their fans try to open animal crossing for the 2 millionth time today.</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>Congratz to the Doom Team!</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>Can I see some ID please?</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>Doom Eternal In A Nutshell</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>Got an epic thing in the mail today</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>The truth</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         title  \\\n",
       "1528                                                                  Mick Gordon simp exposed   \n",
       "759                         Petition to re-rip the Classic Doom Marineâ€™s pants in Doom Eternal   \n",
       "391                                                        Scary movie night! Poor Stitches :(   \n",
       "616                                            Stayed up till 4 AM finishing my magical study!   \n",
       "219                               Thank you Lobo but Isabelle doesn't think the same way.. ðŸ˜”ðŸ˜”ðŸ˜”   \n",
       "404                                              Met Redd today, seems like a pretty nice guy.   \n",
       "466                                                         Hope you guys like my AC grad cap!   \n",
       "131                                                                               I drew Lily!   \n",
       "805                                          Doom Slayer/Samuel Hayden chemistry in a nutshell   \n",
       "938                                           I dunno if something like this was posted before   \n",
       "968                                                              So I Bought A Cacodemon Plush   \n",
       "1024                                                                 Living breathing ammo box   \n",
       "1213                                                           Channel your inner Slayer, king   \n",
       "81                                                                           Is this a pigeon?   \n",
       "70    Nintendo watching their fans try to open animal crossing for the 2 millionth time today.   \n",
       "1184                                                                Congratz to the Doom Team!   \n",
       "1261                                                                 Can I see some ID please?   \n",
       "1163                                                                Doom Eternal In A Nutshell   \n",
       "1220                                                       Got an epic thing in the mail today   \n",
       "209                                                                                  The truth   \n",
       "\n",
       "         ac   doom  \n",
       "1528  False   True  \n",
       "759   False   True  \n",
       "391    True  False  \n",
       "616    True  False  \n",
       "219    True  False  \n",
       "404    True  False  \n",
       "466    True  False  \n",
       "131    True  False  \n",
       "805   False   True  \n",
       "938   False   True  \n",
       "968   False   True  \n",
       "1024  False   True  \n",
       "1213  False   True  \n",
       "81     True  False  \n",
       "70     True  False  \n",
       "1184  False   True  \n",
       "1261  False   True  \n",
       "1163  False   True  \n",
       "1220  False   True  \n",
       "209    True  False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARN AC IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_image_ac = ImageDataLoaders.from_df(df_train, fn_col='path', label_col='ac', item_tfms=Resize(224), bs=32, folder=IMAGES_PATH)\n",
    "# learn_image_ac = cnn_learner(data_image_ac, resnet34, metrics=error_rate)\n",
    "# learn_image_ac.fine_tune(5)\n",
    "# learn_image_ac.export('../models/learn_image_ac_500.pkl')\n",
    "learn_image_ac = load_learner('../models/learn_image_ac_500.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARN DOOM IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_image_doom = ImageDataLoaders.from_df(df_train, fn_col='path', label_col='doom', item_tfms=Resize(224), bs=32, folder=IMAGES_PATH)\n",
    "# learn_image_doom = cnn_learner(data_image_doom, resnet34, metrics=error_rate)\n",
    "# learn_image_doom.fine_tune(5)\n",
    "# learn_image_doom.export('../models/learn_image_doom_500.pkl')\n",
    "learn_image_doom = load_learner('../models/learn_image_doom_500.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, label_column):\n",
    "        self.data_ = data[['title', label_column]].copy().reset_index()\n",
    "        self.label_column = label_column\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.data_.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            str(self.data_.loc[idx]['title']),\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long), \n",
    "            'labels': torch.tensor(self.data_.loc[idx][self.label_column], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# def compute_metrics(pred):\n",
    "#     labels = pred.label_ids\n",
    "#     preds = pred.predictions.argmax(-1)\n",
    "#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "#     acc = accuracy_score(labels, preds)\n",
    "#     return {\n",
    "#         'accuracy': acc,\n",
    "#         'f1': f1,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall\n",
    "#     }\n",
    "\n",
    "# images_train, images_test, text_train, text_test = get_sets(10)\n",
    "\n",
    "# model_bert_ac = BertForSequenceClassification.from_pretrained(\n",
    "#     'bert-base-uncased', \n",
    "#     num_labels=2\n",
    "# )\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=2,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=64,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     evaluate_during_training=True,\n",
    "#     logging_dir='./logs'\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model_bert_ac,\n",
    "#     args=training_args,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     train_dataset=TextDataset(text_train, 'ac'),\n",
    "#     eval_dataset=TextDataset(text_test, 'ac')\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict([tokenizer('Mullet Slayer dont got shit on Buscemi Marauder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train, images_test, text_train, text_test = get_sets(750)\n",
    "text_train['ac'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def train_madel(text_train):\n",
    "    batch_size = 16\n",
    "    seed_val = 42\n",
    "    epochs = 4\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        TextDataset(text_train, 'ac'),\n",
    "        batch_size = batch_size \n",
    "    )\n",
    "\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", \n",
    "        num_labels = 2\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "    )\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0,\n",
    "                                                num_training_steps = total_steps)\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            model.zero_grad()        \n",
    "            loss, logits, *_ = model(\n",
    "                batch['input_ids'].to(device),\n",
    "                attention_mask=batch['attention_mask'].to(device),\n",
    "                token_type_ids=None,\n",
    "                labels=batch['labels'].to(device)\n",
    "            )\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        model.eval()\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ba8fbdc92f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         out_ = model(\n\u001b[1;32m      4\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(validation_dataloader):\n",
    "    with torch.no_grad():        \n",
    "        out_ = model(\n",
    "            batch['input_ids'].to(device),\n",
    "            attention_mask=batch['attention_mask'].to(device),\n",
    "            token_type_ids=None\n",
    "        )\n",
    "        acc = (out_[0].numpy().argmax(axis=1) == batch['labels'].numpy()).sum() / len(batch['labels'])\n",
    "        print(f'{i} = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/cegf/.virtualenvs/new_aka_sl/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.70\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.67\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.52\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.57\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "images_train, images_test, text_train, text_test = get_sets(10)\n",
    "model_2 = train_madel(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 0.40625\n",
      "1 = 0.375\n",
      "2 = 0.5625\n",
      "3 = 0.5\n",
      "4 = 0.53125\n",
      "5 = 0.59375\n",
      "6 = 0.46875\n",
      "7 = 0.3125\n",
      "8 = 0.53125\n",
      "9 = 0.59375\n",
      "10 = 0.59375\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    TextDataset(text_test, 'ac'),\n",
    "    batch_size = 32 \n",
    ")\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    with torch.no_grad():        \n",
    "        out_ = model_2(\n",
    "            batch['input_ids'].to(device),\n",
    "            attention_mask=batch['attention_mask'].to(device),\n",
    "            token_type_ids=None\n",
    "        )\n",
    "        acc = (out_[0].numpy().argmax(axis=1) == batch['labels'].numpy()).sum() / len(batch['labels'])\n",
    "        print(f'{i} = {acc}')\n",
    "    if i == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
